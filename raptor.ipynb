{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\n",
    "\n",
    "This notebook shows how to use an implementation of RAPTOR with llama-index, leveraging the RAPTOR llama-pack.\n",
    "\n",
    "RAPTOR works by recursively clustering and summarizing clusters in layers for retrieval.\n",
    "\n",
    "There two retrieval modes:\n",
    "- tree_traversal -- traversing the tree of clusters, performing top-k at each level in the tree.\n",
    "- collapsed -- treat the entire tree as a giant pile of nodes, perform simple top-k.\n",
    "\n",
    "See [the paper](https://arxiv.org/abs/2401.18059) for full algorithm details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.5.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-huggingface)\n",
      "  Downloading llama_index_core-0.12.45-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting torch<3.0.0,>=2.1.2 (from llama-index-llms-huggingface)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting transformers<5.0.0,>=4.37.0 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiosqlite (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.14.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jinja2 (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.3.8)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Collecting filelock (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (25.0)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: psutil in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (7.0.0)\n",
      "Collecting click (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading llama_index_llms_huggingface-0.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading llama_index_core-0.12.45-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading banks-2.1.3-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m142.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m207.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, filetype, dirtyjson, wrapt, urllib3, typing-inspection, tqdm, tenacity, sympy, sniffio, setuptools, safetensors, regex, pyyaml, pydantic-core, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, joblib, idna, hf-xet, h11, greenlet, fsspec, frozenlist, filelock, colorama, click, charset_normalizer, certifi, attrs, async-timeout, annotated-types, aiosqlite, aiohappyeyeballs, yarl, typing-inspect, triton, sqlalchemy, requests, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, jinja2, httpcore, griffe, deprecated, anyio, aiosignal, tiktoken, nvidia-cusolver-cu12, llama-index-instrumentation, huggingface-hub, httpx, dataclasses-json, banks, aiohttp, torch, tokenizers, llama-index-workflows, transformers, llama-index-core, accelerate, llama-index-llms-huggingface\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/81\u001b[0m [sniffio]]spection]\n",
      "\u001b[2K    Found existing installation: setuptools 78.1.1━━━━━━━━━━━━\u001b[0m \u001b[32m10/81\u001b[0m [sniffio]\n",
      "\u001b[2K    Uninstalling setuptools-78.1.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/81\u001b[0m [sniffio]\n",
      "\u001b[2K      Successfully uninstalled setuptools-78.1.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/81\u001b[0m [setuptools]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81/81\u001b[0m [llama-index-llms-huggingface]gingface]s]ation]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 accelerate-1.8.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 aiosqlite-0.21.0 annotated-types-0.7.0 anyio-4.9.0 async-timeout-5.0.1 attrs-25.3.0 banks-2.1.3 certifi-2025.6.15 charset_normalizer-3.4.2 click-8.2.1 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filelock-3.18.0 filetype-1.2.0 frozenlist-1.7.0 fsspec-2025.5.1 greenlet-3.2.3 griffe-1.7.3 h11-0.16.0 hf-xet-1.1.5 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.1 idna-3.10 jinja2-3.1.6 joblib-1.5.1 llama-index-core-0.12.45 llama-index-instrumentation-0.2.0 llama-index-llms-huggingface-0.5.0 llama-index-workflows-1.0.1 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.6.3 mypy-extensions-1.1.0 networkx-3.4.2 nltk-3.9.1 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pillow-11.2.1 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 setuptools-80.9.0 sniffio-1.3.1 sqlalchemy-2.0.41 sympy-1.14.0 tenacity-9.1.2 tiktoken-0.9.0 tokenizers-0.21.2 torch-2.7.1 tqdm-4.67.1 transformers-4.53.0 triton-3.3.1 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 wrapt-1.17.2 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.5-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.1)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.12.45)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.20.1)\n",
      "Requirement already satisfied: griffe in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: filelock in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.5)\n",
      "Requirement already satisfied: click in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.2.1)\n",
      "Requirement already satisfied: joblib in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.6.15)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.53.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.7.1)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
      "Requirement already satisfied: greenlet>=1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.2.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: anyio in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.5-py3-none-any.whl (8.9 kB)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sentence-transformers, llama-index-embeddings-huggingface\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [llama-index-embeddings-huggingface]sformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed llama-index-embeddings-huggingface-0.5.5 scikit-learn-1.7.0 scipy-1.15.3 sentence-transformers-4.1.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-huggingface\n",
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.44-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.44 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index) (0.12.45)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.20.1)\n",
      "Requirement already satisfied: griffe in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (4.3.8)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.44->llama-index) (0.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.44->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.4.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.41-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.41 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-cloud-services>=0.6.41->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.2.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.40-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.40 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.39 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: joblib in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading llama_index-0.12.44-py3-none-any.whl (7.1 kB)\n",
      "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_cli-0.4.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
      "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
      "Downloading llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
      "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.34-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.34-py3-none-any.whl (39 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: striprtf, pytz, widgetsnbextension, tzdata, soupsieve, python-dotenv, pypdf, jupyterlab_widgets, jiter, distro, pandas, beautifulsoup4, ipywidgets, openai, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/28\u001b[0m [llama-index]\u001b[0m [llama-index-program-openai]i]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 distro-1.9.0 ipywidgets-8.1.7 jiter-0.10.0 jupyterlab_widgets-3.0.15 llama-cloud-0.1.26 llama-cloud-services-0.6.34 llama-index-0.12.44 llama-index-agent-openai-0.4.12 llama-index-cli-0.4.3 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.34 openai-1.93.0 pandas-2.2.3 pypdf-5.7.0 python-dotenv-1.1.1 pytz-2025.2 soupsieve-2.7 striprtf-0.0.26 tzdata-2025.2 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-huggingface in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (0.5.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.1)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.12.45)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (4.1.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.20.1)\n",
      "Requirement already satisfied: griffe in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: filelock in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.5)\n",
      "Requirement already satisfied: click in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.2.1)\n",
      "Requirement already satisfied: joblib in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.6.15)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.53.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: scipy in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
      "Requirement already satisfied: greenlet>=1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.2.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: anyio in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /storage/group/vxk1/default/muyu_folder/conda/env/raptor/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install llama-index llama-index-packs-raptor llama-index-vector-stores-chroma\n",
    "# !pip install --upgrade transformers\n",
    "!pip install llama-index-embeddings-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.raptor import RaptorPack\n",
    "\n",
    "# optionally download the pack to inspect/modify it yourself!\n",
    "# from llama_index.core.llama_pack import download_llama_pack\n",
    "# RaptorPack = download_llama_pack(\"RaptorPack\", \"./raptor_pack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!wget https://arxiv.org/pdf/2401.18059.pdf -O ./Raptor.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Clusters/Hierarchy Tree\n",
    "\n",
    "Async code (asynchronous code) is code that doesn't execute sequentially from top to bottom. Instead, it allows operations to run in the background without blocking the execution of other code. This enables programs to remain responsive while waiting for time-consuming operations to complete.\n",
    "\n",
    "An event loop is a programming construct that continuously monitors and processes events or messages in a program. It's the core mechanism that enables asynchronous, non-blocking operations in many programming environments. The event loop follows this basic pattern: \n",
    "Wait for something to happen (an event)\n",
    "Process that event when it occurs\n",
    "Repeat - go back to waiting\n",
    "\n",
    "asyncio is Python's built-in library for writing asynchronous code. It allows you to write concurrent code using the async/await syntax.\n",
    "\n",
    "nest_asyncio is a library that patches asyncio to allow nested event loops. This is particularly important in Jupyter notebooks!\n",
    "The Problem:\n",
    "\n",
    "Jupyter notebooks already run their own event loop in the background\n",
    "Normal asyncio doesn't allow creating a new event loop when one is already running\n",
    "This causes errors like: RuntimeError: This event loop is already running\n",
    "\n",
    "What does nest_asyncio.apply() do?\n",
    "Patches the asyncio event loop to allow nesting\n",
    "Enables running async code inside environments that already have an event loop (like Jupyter)\n",
    "Prevents RuntimeError when libraries try to create their own event loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First line is importing SimpleDirectoryReader class, which is LlamaIndex's primary tool for loading various document types (PDFs, Word docs, text files, etc.) into a format that can be processed.\n",
    "\n",
    "second line loads the pdf, .load_data() actually reads the PDF and converts it into LlamaIndex Document objects, each Document contains:\n",
    "\n",
    "The text content extracted from the PDF\n",
    "Metadata (filename, page numbers, etc.)\n",
    "\n",
    "A unique document ID\n",
    "\n",
    "Returns a list of documents:\n",
    "documents becomes a list of Document objects\n",
    "For a single PDF, this is typically one Document object containing all the text\n",
    "\n",
    "this loaded document will then be:\n",
    "\n",
    "Split into chunks by the SentenceSplitter\n",
    "Embedded using the embedding model\n",
    "Clustered and summarized hierarchically by RAPTOR\n",
    "Stored in the vector database for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# documents = SimpleDirectoryReader(input_files=[\"./Raptor.pdf\"]).load_data()\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=\"/storage/home/mfp5696/vxk_group/250630_nlp_hallucination/documents\",\n",
    "    recursive=True,\n",
    ")\n",
    "\n",
    "documents = []\n",
    "for docs in reader.iter_data():\n",
    "    for doc in docs:\n",
    "        documents.append(doc)\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "Splits documents into smaller chunks\n",
    "\n",
    "Chroma is an open-source vector database designed specifically for AI applications. A specialized database for storing and searching embeddings (numerical representations of text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA A100-PCIE-40GB\n",
      "Memory: 42.41 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccc2c8e532a41b69e2ff52e3a4d0044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for level 0.\n",
      "Performing clustering for level 0.\n",
      "Generating summaries for level 0 with 1227 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import chromadb\n",
    "\n",
    "#Creates a database that persists on disk\n",
    "client = chromadb.PersistentClient(path=\"./raptor_paper_db\")\n",
    "\n",
    "#Creates a named collection \"raptor\"\n",
    "collection = client.get_or_create_collection(\"raptor\")\n",
    "\n",
    "#LlamaIndex wrapper around Chroma, provides unified interface for vector operations\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "#Llama models\n",
    "LLAMA2_7B = \"meta-llama/Llama-2-7b-hf\"\n",
    "LLAMA2_7B_CHAT = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "LLAMA2_13B = \"meta-llama/Llama-2-13b-hf\"\n",
    "LLAMA2_13B_CHAT = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "LLAMA2_70B = \"meta-llama/Llama-2-70b-hf\"\n",
    "LLAMA2_70B_CHAT = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "selected_model = LLAMA2_13B_CHAT\n",
    "\n",
    "\n",
    "raptor_pack = RaptorPack(\n",
    "    documents, \n",
    "    embed_model=HuggingFaceEmbedding(\n",
    "        model_name=\"intfloat/e5-base-v2\",\n",
    "        query_instruction=\"query: \", # used for embedding queries E5 models\n",
    "        text_instruction=\"passage: \",\n",
    "        #embed_batch_size=64\n",
    "    ),  # used for embedding clusters\n",
    "    #llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),  # used for generating summaries\n",
    "    llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=2048,\n",
    "    generate_kwargs={\"temperature\": 0.1,},\n",
    "    #query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=selected_model,\n",
    "    model_name=selected_model,\n",
    "    device_map=\"auto\",\n",
    "    # change these settings below depending on your GPU\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "),\n",
    "    vector_store=vector_store,  # used for storage\n",
    "    similarity_top_k=2,  # top k for each layer, or overall top-k for collapsed\n",
    "    mode=\"collapsed\",  # sets default mode\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=400, chunk_overlap=50)\n",
    "    ],  # transformations applied for ingestion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Specifically, RAPTOR’s F-1 scores are at least 1.8% points higher than DPR and at least 5.3% points\n",
      "higher than BM25.\n",
      "Retriever GPT-3 F-1 Match GPT-4 F-1 Match UnifiedQA F-1 Match\n",
      "Title + Abstract 25.2 22.2 17.5\n",
      "BM25 46.6 50.2 26.4\n",
      "DPR 51.3 53.0 32.1\n",
      "RAPTOR 53.1 55.7 36.6\n",
      "Table 4: Comparison of accuracies on the QuAL-\n",
      "ITY dev dataset for two different language mod-\n",
      "els (GPT-3, UnifiedQA 3B) using various retrieval\n",
      "methods. RAPTOR outperforms the baselines of\n",
      "BM25 and DPR by at least 2.0% in accuracy.\n",
      "Model GPT-3 Acc. UnifiedQA Acc.\n",
      "BM25 57.3 49.9\n",
      "DPR 60.4 53.9\n",
      "RAPTOR 62.4 56.6\n",
      "Table 5: Results on F-1 Match scores of various\n",
      "models on the QASPER dataset.\n",
      "Model F-1 Match\n",
      "LongT5 XL (Guo et al., 2022) 53.1\n",
      "CoLT5 XL (Ainslie et al., 2023) 53.9\n",
      "RAPTOR + GPT-4 55.7Comparison to State-of-the-art Systems\n",
      "Building upon our controlled comparisons,\n",
      "we examine RAPTOR’s performance relative\n",
      "to other state-of-the-art models.\n"
     ]
    }
   ],
   "source": [
    "nodes = raptor_pack.run(\"What baselines is raptor compared against?\", mode=\"collapsed\")\n",
    "print(len(nodes))\n",
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved parent IDs from level 2: ['cc3b3f41-f4ca-4020-b11f-be7e0ce04c4f']\n",
      "Retrieved 1 from parents at level 2.\n",
      "Retrieved parent IDs from level 1: ['a4ca9426-a312-4a01-813a-c9b02aefc7e8']\n",
      "Retrieved 2 from parents at level 1.\n",
      "Retrieved parent IDs from level 0: ['63126782-2778-449f-99c0-1e8fd90caa36', 'd8f68d31-d878-41f1-aeb6-a7dde8ed5143']\n",
      "Retrieved 4 from parents at level 0.\n",
      "4\n",
      "Specifically, RAPTOR’s F-1 scores are at least 1.8% points higher than DPR and at least 5.3% points\n",
      "higher than BM25.\n",
      "Retriever GPT-3 F-1 Match GPT-4 F-1 Match UnifiedQA F-1 Match\n",
      "Title + Abstract 25.2 22.2 17.5\n",
      "BM25 46.6 50.2 26.4\n",
      "DPR 51.3 53.0 32.1\n",
      "RAPTOR 53.1 55.7 36.6\n",
      "Table 4: Comparison of accuracies on the QuAL-\n",
      "ITY dev dataset for two different language mod-\n",
      "els (GPT-3, UnifiedQA 3B) using various retrieval\n",
      "methods. RAPTOR outperforms the baselines of\n",
      "BM25 and DPR by at least 2.0% in accuracy.\n",
      "Model GPT-3 Acc. UnifiedQA Acc.\n",
      "BM25 57.3 49.9\n",
      "DPR 60.4 53.9\n",
      "RAPTOR 62.4 56.6\n",
      "Table 5: Results on F-1 Match scores of various\n",
      "models on the QASPER dataset.\n",
      "Model F-1 Match\n",
      "LongT5 XL (Guo et al., 2022) 53.1\n",
      "CoLT5 XL (Ainslie et al., 2023) 53.9\n",
      "RAPTOR + GPT-4 55.7Comparison to State-of-the-art Systems\n",
      "Building upon our controlled comparisons,\n",
      "we examine RAPTOR’s performance relative\n",
      "to other state-of-the-art models.\n"
     ]
    }
   ],
   "source": [
    "nodes = raptor_pack.run(\n",
    "    \"What baselines is raptor compared against?\", mode=\"tree_traversal\"\n",
    ")\n",
    "print(len(nodes))\n",
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "\n",
    "Since we saved to a vector store, we can also use it again! (For local vector stores, there is a `persist` and `from_persist_dir` method on the retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.raptor import RaptorRetriever\n",
    "\n",
    "retriever = RaptorRetriever(\n",
    "    [],\n",
    "    embed_model=OpenAIEmbedding(\n",
    "        model=\"text-embedding-3-small\"\n",
    "    ),  # used for embedding clusters\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),  # used for generating summaries\n",
    "    vector_store=vector_store,  # used for storage\n",
    "    similarity_top_k=2,  # top k for each layer, or overall top-k for collapsed\n",
    "    mode=\"tree_traversal\",  # sets default mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using a default vector store\n",
    "# retriever.persist(\"./persist\")\n",
    "# retriever = RaptorRetriever.from_persist_dir(\"./persist\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever, llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What baselines was RAPTOR compared against?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 and DPR\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
